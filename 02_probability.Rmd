# Introduction to Probability

## Chapter mission

Why should we study probability? What are probabilities? How do you find them? What are the
main laws of probabilities? How about some fun examples where probabilities are used to solve
real-life problems?

## Definitions of probability

### Why should we study probability?

Probabilities are often used to express the uncertainty of events of interest happening. For example,
we may say that: (i) it is highly likely that Liverpool will retain the premiership title this season
or to be more specific, I think there is more than an 80% chance that Liverpool will keep the title;
(ii) the probability of a tossed fair coin landing heads is 0.5. So it is clear that probabilities mean
different things to different people. As we have seen in the previous chapter, there is uncertainty
everywhere. Hence, probabilities are used as tools to quantify the associated uncertainty. The
theory of statistics has its basis in the mathematical theory of probability. A statistician must
be fully aware of what probability means to him/her and what it means to other people. In this
lecture we will learn the basic definitions of probability and how to find them.

### Two types of probabilities: subjective and objective

The two examples above, Liverpool and tossing a coin, convey two different interpretations of
probability. The Liverpool probability is the commentator's own subjective belief, isn't it? The
commentator certainly has not performed a large experiment involving all the 20 teams over the
whole (future) season under all playing conditions, players, managers and transfers. This notion
is known as subjective probability. Subjective probability gives a measure of the plausibility of
the proposition, to the person making it, in the light of past experience (e.g. Liverpool are the
current champions) and other evidence (e.g. they spent the maximum amount of money buying
players). There are plenty of other examples, e.g. I think there is a 70% chance that the FTSE
100 will rise tomorrow, or according to the Met Office there is a 40% chance that we will have a
white Christmas this year in Southampton. Subjective probabilities are nowadays used cleverly
in a statistical framework called Bayesian inference. Such methods allow one to combine expert
opinion and evidence from data to make the best possible inferences and prediction. Unfortunately
discussion of Bayesian inference methods is beyond the scope of this module, although we will talk
about it when possible.

The second definition of probability comes from the long-term relative frequency of a result of
a random experiment (e.g. coin tossing) which can be repeated an infinite number of times under
essentially similar conditions. First we give some essential definitions.

**Random experiments**. The experiment is random because in advance we do not know exactly
what outcome the experiment will give, even though we can write down all the possible outcomes
which together are called the **sample space** ($S$). For example, in a coin tossing experiment, $S
= \{\text{head}, \text{tail}\}$. If we toss two coins together, 
$S = \{\text{HH}, \text{HT}, \text{TH}, \text{TT}\}$ where $\text{H}$ and $\text{T}$ denote
respectively the outcome head and tail from the toss of a single coin.

<!-- TODO: check consistency of bold or italics for definitions -->

**Event**. An event is defined as a particular result of the random experiment. For example, 
$\text{HH}$
(two heads) is an event when we toss two coins together. Similarly, at least one head e.g. 
$\{\text{HH}, \text{HT}, \text{TH}\}$ is an event as well. 
Events are denoted by capital letters $A, B, C, \ldots$ or $A_1, B_1, A_2$ etc., and
a single outcome is called an **elementary event**, e.g. $\text{HH}$. 
An event which is a group of elementary
events is called a **composite event**, e.g. at least one head. How to determine the probability of a
given event $A$, $P\{A\}$, is the focus of probability theory.

**Probability as relative frequency**. Imagine we are able to repeat a random experiment
under identical conditions and count how many of those repetitions result in the event $A$. The
relative frequency of $A$, i.e. the ratio
\[\frac{\text{the number of repetitions resulting in $A$}}{\text{total number of repetitions}},\]
approaches a fixed limit value as the number of repetitions increases. This limit value is defined as
$P\{A\}$.

As a simple example, in the experiment of tossing a particular coin, suppose we are interested
in the event $A$ of getting a 'head'. We can toss the coin 1000 times (i.e. do 1000 replications of
the experiment) and record the number of heads out of the 1000 replications. Then the relative
frequency of $A$ out of the 1000 replications is the proportion of heads observed.
Sometimes, however, it is much easier to find $P\{A\}$ by using some 'common knowledge' about
probability. For example, if the coin in the example above is fair 
(i.e. $P\{\text{head}\} = P\{\text{tail}\})$, then
this information and the common knowledge that $P\{\text{head}\}+P\{\text{tail}\} = 1$
immediately imply that
$P\{\text{head}\} = 0.5$ and $P\{\text{tail}\} = 0.5$. Next, the essential 
'common knowledge' about probability
will be formalized as the axioms of probability, which form the foundation of probability theory.
But before that, we need to learn a bit more about the event space (collection of all events).

### Union, intersection, mutually exclusive and complementary events


For us to proceed we need to establish parallels between probability theory and set theory, which
is taught in calculus. The sample space S is called the whole set and it is composed of all possible
elementary events (outcomes from a single replicate).

::: {.example name="Fast food service time" #die-throw}
Roll a six-faced die and observe the score on the uppermost face.
Here $S = \{1, 2, 3, 4, 5, 6\}$, which is composed of six elementary events.

The **union** of two given events $A$ and B, denoted as ($A$ or $B$) or $A \cup B$, 
consists of the outcomes
that are either in A or B or both. 'Event $A \cup B$ occurs' means 
'either $A$ or $B$ occurs or both occur'.
:::

For example, in Example \@ref(exm:die-throw), 
suppose $A$ is the event that *an even number is observed*. This
event consists of the set of outcomes 2, 4 and 6, i.e. $A = \{\text{an even number}\} = \{2, 4, 6\}$.
Suppose $B$ is the event that *a number larger than 3 is observed*. This event consists of the 
outcomes 4, 5 and 6, i.e. $B = \{\text{a number larger than 3}\} = \{4, 5, 6\}$. 
Hence the event $A \cup B =
\{\text{an even number or a number larger than 3}\} = \{2, 4, 5, 6\}$. 
Clearly, when a $6$ is observed, both $A$
and $B$ have occurred.

The **intersection** of two given events $A$ and $B$, denoted as ($A$ and $B$) or $A \cap B$, 
consists of the
outcomes that are common to both $A$ and $B$. 'Event $A \cap B$ occurs' means 'both $A$ and $B$ occur'. For
example, in Example \@ref(exm:die-throw), 
$A \cap B = \{4, 6\}$. Additionally, if $C = \{\text{a number less than 6}\} = \{1, 2, 3, 4, 5\}$,
the intersection of events $A$ and $C$ is the event $A \cap C = \{\text{an even number less than 6}\} = \{2, 4\}$.

The union and intersection of two events can be generalized in an obvious way to the union and
intersection of more than two events.

Two events $A$ and $D$ are said to be mutually exclusive if $A \cap D = \emptyset$, where $\emptyset$ denotes the empty
set, i.e. $A$ and $D$ have no outcomes in common. Intuitively, '$A$ and $D$ are mutually exclusive'
means '$A$ and $D$ cannot occur simultaneously in the experiment'.

In Example \@ref(exm:die-throw), 
if $D = \{\text{an odd number}\} = \{1, 3, 5\}$, then $A \cap D = \emptyset$ and so $A$ and $D$ are
mutually exclusive. As expected, $A$ and $D$ cannot occur simultaneously in the experiment.

For a given event $A$, the complement of $A$ is the event that consists of all the outcomes not in
$A$ and is denoted by $A^\prime$ . Note that $A \cup A^\prime = S$ and $A \cap A^\prime = \emptyset$.

<!-- TODO: add mutually exclusive, union and intersection Venn diagrams -->

Thus, we can see the parallels between Set theory and Probability theory:


| Set theory       | Probability theory |
|------------------|--------------------|
| Space            | Sample space       |
| Element or point | Elementary event   |
| Set              | Event              |

### Axioms of probability

Here are the three axioms of probability:

**A1** $P\{S\}=1$.  
**A2** $0 \leq P\{A\} \leq 1$ for any event $A$.  
**A3** $P\{A \cup B\}=P\{A\}+P\{B\}$ provided that $A$ and $B$ are mutually exclusive events.

Here are some of the consequences of the axioms of probability:

(1) For any event $A, P\{A\}=1-P\left\{A^{\prime}\right\}$.
(2) From (1) and Axiom A 1, $P\{0\}=1-P\{S\}=0$. Hence if $A$ and $B$ are mutually exclusive events, then $P\{A \cap B\}=0$.
(3) If $D$ is a subset of $E, D \subset E$, then $P\left\{E \cap D^{\prime}\right\}=P\{E\}-P\{D\}$ which implies for arbitrary events $A$ and $B, P\left\{A \cap B^{\prime}\right\}=P\{A\}-P\{A \cap B\}$.
(4) It can be shown by mathematical induction that Axiom A3 holds for more than two mutually exclusive events:
$$
P\left\{A_{1} \cup A_{2} \cup \cdots \cup A_{k}\right\}=P\left\{A_{1}\right\}+P\left\{A_{2}\right\}+\ldots+P\left\{A_{k}\right\}
$$
provided that $A_{1}, \ldots, A_{k}$ are mutually exclusive events.
Hence, the probability of an event A is the sum of the probabilities of the individual outcomes that make up the event.
(5) For the union of two arbitrary events, we have the General addition rule: For any two events $A$ and $B$
$$
P\{A \cup B\}=P\{A\}+P\{B\}-P\{A \cap B\} .
$$
**Proof**: We can write $A \cup B=\left(A \cap B^{\prime}\right) \cup(A \cap B) \cup\left(A^{\prime} \cap B\right)$. All three of these are mutually exclusive events. Hence,
$$
\begin{aligned}
P\{A \cup B\} &=P\left\{A \cap B^{\prime}\right\}+P\{A \cap B\}+P\left\{A^{\prime} \cap B\right\} \\
&=P\{A\}-P\{A \cap B\}+P\{A \cap B\}+P\{B\}-P\{A \cap B\} \\
&=P\{A\}+P\{B\}-P\{A \cap B\} .
\end{aligned}
$$
(6) The sum of the probabilities of all the outcomes in the sample space $S$ is 1 .

### Application to an experiment with equally likely outcomes

For an experiment with $N$ equally likely possible outcomes, the axioms (and the consequences
above) can be used to find $P\{A\}$ of any event $A$ in the following way.

From consequence (4), we assign probability $1/N$ to each outcome.

For any event $A$, we find $P\{A\}$ by adding up $1/N$ for each of the outcomes in event $A$:
\[P \{A\} = \frac{\text{number of outcomes in $A$}}
{\text{total number of possible outcomes of the experiment}}.\]

Return to Example \@ref(exm:die-throw)
where a six-faced die is rolled. Suppose that one wins a bet if a 6 is
rolled. Then the probability of winning the bet is $1/6$ as there are six possible outcomes in the
sample space and exactly one of those, 6, wins the bet. Suppose $A$ denotes the event that an
even-numbered face is rolled. Then $P\{A\} = 3/6 = 1/2$ as we can expect.

::: {.example name="Dice throw"}
Roll 2 distinguishable dice and observe the scores. Here 
\[S =
\{(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), . . . , (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)\}\]
which consists of 36
possible outcomes or elementary events, $A_1, \ldots , A_{36}$.
What is the probability of the outcome $6$ in
both the dice? The required probability is $1/36$. What is the probability that the sum of the two
dice is greater than 6? How about the probability that the sum is less than any number, e.g. 8?  
**Hint**: Write down the sum for each of the 36 outcomes and then find the probabilities asked just
by inspection. Remember, each of the 36 outcomes has equal probability $1/36$.
:::

#### Take home points

This lecture has laid the foundation for studying probability. We discussed two types of probabilities, subjective and objective by relative frequencies. Using three axioms of probability we have
derived the elementary rules for probability. We then discussed how we can use elementary laws of
probability to find the probabilities of some events from the dice throw example.

The next lecture will continue to find probabilities using specialist counting techniques called
permutation and combination. This will allow us to find probabilities in a number of practical
situations.


## Using combinatorics to find probability

We will learn common counting techniques. Suppose there are 4 boys and 6 girls available for a
committee membership, but there are only 3 posts. How many possible committees can be formed?
How many of those will be girls only?
The UK National Lottery selects 6 numbers at random from 1 to 49. I bought one ticket -- what
is the probability that I will win the jackpot?


### Multiplication rule of counting

To complete a specific task, one has to complete $k(\geq 1)$ sub-tasks sequentially. If there are 
$n_i$
different ways to complete the $i$th sub-task ($i = 1, \ldots, k$) then there are 
$n_1 \times n_2 \times \dots \times n_k$ different
ways to complete the task.

::: {.example name="Counting"}
Suppose there are 7 routes to London from Southampton and
then there are 5 routes to Cambridge out of London. How many ways can
I travel to Cambridge from Southampton via London? The answer is
obviously 35. 
:::


#### The number of permutations of $k$ from $n$: $P(n, k)$

<!-- TODO: this seems to refer to an example not yet introduced?! -->

The task is to select $k(\geq 1)$ from the $n (n \geq k)$ available people and sit the 
$k$ selected people in $k$
(different) chairs. By considering the $i$th sub-task as selecting a person to sit in
the $i$th chair ($i = 1, \ldots, k$), it follows directly from the multiplication rule above that there are $n(n-1) \ldots (n-[k -1])$
ways to complete the task. The number $n(n-1) \ldots (n-[k-1])$
is called the number of permutations
of $k$ from $n$ and denoted by
\[P(n, k) = n(n - 1) \ldots (n - [k - 1]).\]
In particular, when $k = n$ we have $P(n, n) = n(n - 1) \ldots 1$, which 
is called '$n$ factorial' and denoted
as $n!$. Note that $0!$ is defined to be $1$. It is clear that
\[P(n, k)=n(n-1) \ldots(n-[k-1])=\frac{n(n-1) \ldots(n-[k-1]) \times(n-k) !}{(n-k) !}=\frac{n !}{(n-k) !}.\]

::: {.example name="Football"}
How many possible rankings are there for the 20 football teams in
the premier league at the end of a season? This number is given by $P(20, 20) = 20!$, which is a huge
number! How many possible permutations are there for the top 4 positions who will qualify to play
in Europe in the next season? This number is given by $P(20, 4) = 20 \times 19 \times 18 \times 17$.
:::

#### The number of combinations of $k$ from $n$: $\binom{n}{k}$


The task is to select $k(\geq 1)$ from the $n$ ($n \geq k$) available people. 
Note that this task does NOT
involve sitting the $k$ selected people in $k$ (different) chairs. We want to find the number of possible
ways to complete this task, which is denoted as $\binom{n}{k}$.

For this, let us reconsider the task of "selecting $k(\geq 1)$ from the $n$ ($n \geq k$) available people and
sitting the $k$ selected people in $k$ (different) chairs", which we already know from the discussion
above has $P(n, k)$ ways to complete.
Alternatively, to complete this task, one has to complete two sub-tasks sequentially. The first
sub-task is to select $k(\geq 1)$ from the $n$ ($n \geq k$) available people, which has $\binom{n}{k}$
ways. The second
sub-task is to sit the $k$ selected people in $k$ (different) chairs, which has $k!$ ways. 
It follows directly
from the multiplication rule that there are $\binom{n}{k} \times k!$ ways
to complete the task. Hence we have
\[ P(n, k)= \binom{n}{k} \times k!\]
so
\[\binom{n}{k} =\frac{P(n, k)}{k!}=\frac{n!}{(n-k)! k!}.\]

::: {.example name="Football"}
How many possible ways are there to choose 3 teams for the bottom
positions of the premier league table at the end of a season? This number is given by 
$\binom{20, 3} = 20 \times 19 \times 18/3!$, which does not take into consideration the rankings of the three bottom teams.
:::

:::{.example name="Microchip" #microchip}
A box contains 12 microchips of which 4 are faulty. A sample of size
3 is drawn from the box without replacement.

- How many selections of 3 can be made? $\binom{12}{3}$
- How many samples have all 3 chips faulty? $\binom{4}{3}$.
- How many selections have exactly 2 faulty chips? $\binom{8}{1} \binom{4}{2}$
- How many samples of 3 have 2 or more faulty chips? $\binom{8}{1} \binom{4}{2} + \binom{4}{3}$

:::

More examples and details regarding the combinations are provided in Section ??. It is
strongly recommended to read that section now.
<!-- TODO: add reference -->



### Calculation of probabilities of events under sampling 'at random'

For the experiment of 'selecting a sample of size $n$ from a box of $N$ items without replacement',
a sample is said to be selected at random if all the possible samples of size n are equally likely to
be selected. All the possible samples are then equally likely outcomes of the experiment and so
assigned equal probabilities.

:::{.example name="Microchip continued"}
In Example \@ref(exm:microchip) assume that 3 microchips are selected at
random without replacement. Then

- each outcome (sample of size $3$) has probability $1/\binom{12}{3}$.
- $P\{\text{all 3 selected microchips are faulty}\} = \binom{4}{3}/ \binom{12}{3}$.
- $P\{\text{2 chips are faulty}\} = \binom{8}{1} \binom{4}{2}/ \binom{12}{3}$.
- $P\{\text{2 or more chips are faulty}\} = \big(\binom{8}{1} \binom{4}{2} + \binom{4}{3}\big)/\binom{12}{3}.$

:::

### A general 'urn problem'

Example \@ref(exm:microchip) is one particular case of the following general 
urn problem which can be solved by the
same technique.
A sample of size $n$ is drawn at random without replacement from a box of $N$ items containing
a proportion $p$ of defective items.

- How many defective items are in the box? $N p$. How many good items are there? $N (1 - p)$.
Assume these to be integers.
- The probability of exactly $x$ defective items in the sample of $n$ items is
\[\frac{\binom{Np}{x} \binom{N(1-p)}{n-x}}{\binom{N}{n}}.\]
- Which values of $x$ (in terms of $N$, $n$ and $p$) make this expression well defined?
We'll see later that these values of $x$ and the corresponding probabilities make up what is called
the *hyper-geometric* distribution.

:::{.example name="Selecting a committee"}
There are 10 students available for a committee of
which 4 are men and 6 are women. A random sample of 3 students are chosen to form the committee
--- what is the probability that exactly one is a man?
The total number of possible outcomes of the experiment is equal to the number of ways of
selecting 3 students from 10 and is given by $\binom{10}{3}$. 
The number of outcomes in the event 'exactly one
is a man' is equal to the number of ways of selecting 3 students from 10 with exactly one man, and
given by $\binom{4}{1} \binom{6}{2}$
Hence
\begin{align*}
P {\text{exactly one man}} &= \frac{\text{number of ways of selecting one man and two women}}
 {\text{number of ways of selecting 3 students}} \\
&= \frac{\binom{4}{1} \binom{6}{2}}{\binom{10}{3}} = \frac{4 \times 15}{120} = \frac{1}{2}
\end{align*}

:::

<!-- TODO: check if lottery process has change? -->

:::{.example name="The National Lottery"}
In Lotto, a winning ticket has six numbers from 1 to 49
matching those on the balls drawn on a Wednesday or Saturday evening. The 'experiment' consists
of drawing the balls from a box containing 49 balls. The 'randomness', the equal chance of any set
of six numbers being drawn, is ensured by the spinning machine, which rotates the balls during the
selection process. What is the probability of winning the jackpot?
The total number of possible selections of six balls/numbers is $\binom{49}{6}$
There is only 1 selection for winning the jackpot. Hence
\[P\{\text{jackpot}\} = \frac{1}{\binom{49}{6}} = 7.15 \times 10^{-8},\]
which is roughly 1 in 13.98 million.

Other prizes are given for fewer matches. The corresponding probabilities are:
\begin{align*}
P \{\text{$5$ matches}\} &= \frac{\binom{6}{5} \binom{43}{1}}{\binom{49}{6}} = 1.84 \times 10^{-5}. \\
P \{\text{$4$ matches}\} &= \frac{\binom{6}{4} \binom{43}{2}}{\binom{49}{6}} = 0.0009686197.\\
P \{\text{$3$ matches}\} &=\frac{\binom{6}{3} \binom{43}{3}}{\binom{49}{6}} = 0.0176504.
\end{align*}

There is one other way of winning by using the bonus ball --- matching 5 of the selected 6 balls
plus matching the bonus ball. The probability of this is given by
\[P \{\text{$5$ matches + bonus}\} = \frac{6}{\binom{49}{6}} = 4.29 \times 10-7 .\]

Adding all these probabilities of winning some kind of prize together gives
\[P \{\text{winning}\} ≈ 0.0186 ≈ 1/53.7.\]
So a player buying one ticket each week would expect to win a prize, (most likely a £10 prize for
matching three numbers) about once a year.

:::

